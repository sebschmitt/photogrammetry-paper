% !TeX root = ../../main.tex
\ohead{Sebastian Schmitt}

\chapter{Umsetzung}\label{sec:implementation}
Im folgenden wird der Aufbau des Projektes sowie verwendete Bibliotheken erläutert.
Zusätzlich wird auf die Implementierung der einzelnen Schritte der SfM Pipeline eingegangen.

\section{Projektstruktur}
Die Applikation wird in C++ entwickelt.
Auch wenn Performance kein Ziel ist, wurde C++ gewählt um eine höhere Performance zu erreichen.
Einzige Abhängigkeit ist die offene Bibliothek OpenCV, siehe dazu \ref{sec:opencv}.
Zur Buildsteuerung wird das quelloffene Tool CMake\footnote{https://cmake.org/} verwendet.

Das Projekt ist folgendermaßen strukturiert:

\dirtree{%
.1 yapgt.
.2 include \ldots{} \begin{minipage}[t]{12cm}
Header-Dateien
\end{minipage}.
.2 resources \ldots{} \begin{minipage}[t]{12cm}
Bilder zum Testen von Kalibrierung und Feature-Matching
\end{minipage}.
.2 src \ldots{} \begin{minipage}[t]{12cm}
Implementierung
\end{minipage}.
.2 CMakeLists.txt \ldots{} \begin{minipage}[t]{12cm}
CMake Konfiguration
\end{minipage}.
}


\section{OpenCV}\label{sec:opencv}
Es wird OpenCV in der Version 4.2.0 mit dem Modul OpenCV Contrib verwendet.
OpenCV Contrib beinhaltet OpenCV Module, welche jedoch nicht stabil genug sind um Teil der offiziellen OpenCV Distribution zu sein \cite[README.md]{opencv_2013}.
OpenCV wurde mit folgenden Optionen kompiliert:
\begin{itemize}
	\item OPENCV\_EXTRA\_MODULES\_PATH um den Pfad zu OpenCV Contrib festzulegen
	\item OPENCV\_ENABLE\_NONFREE um auch nicht freie Algorithmen zu kompilieren
\end{itemize}
Auch wenn es Anforderung ist nur freie Bibliotheken zu verwenden, ist der Flag OPENCV\_ENABLE\_NON\_FREE notwendig.
Der in dieser Arbeit verwendete Algorithmus Scale-Invariant Feature Transform (SIFT) war bis 06. März 2020 von der University of British Columbia patentiert\footnote{siehe dazu https://patents.google.com/patent/US6711293} und ist daher in der verwendeten OpenCV Version nur mit OPENCV\_ENABLE\_NON\_FREE nutzbar.
SIFT ist Teil des Moduls Features2D extra (xfeatures2d) welches Teil von OpenCV Contrib ist und sowohl experimentelle als auch nicht freie Algorithmen beinhaltet.

Um die Applikation auch nutzen zu können ohne vorab OpenCV zu installieren oder zu kompilieren wurde CMake angewiesen, OpenCV statisch zu linken (siehe \autoref{lst:cmake_opencv_static}, Zeilen 1-4).
Zusätzlich kopiert CMake alle gelinkten Bibliotheken, auch wenn diesen nicht referenziert werden, in den Ausgabeordner, damit diese nicht von Hand kopiert werden müssen (\autoref{lst:cmake_opencv_static}, Zeilen 6-8).

\begin{lstlisting}[numbers=left, breaklines=true,breakatwhitespace=false,label=lst:cmake_opencv_static, caption=Ausschnitt von CMakeLists.txt um OpenCV statisch zu linken]
set(OPENCV_STATIC ON)
find_package(OpenCV REQUIRED)
[..]
target_link_libraries(yapgt ${OpenCV_LIBS})
[..]
foreach(CVLib ${OpenCV_LIBS})
    file(COPY ${_OpenCV_LIB_PATH}/${CVLib}${OpenCV_VERSION_MAJOR}${OpenCV_VERSION_MINOR}${OpenCV_VERSION_PATCH}d.dll DESTINATION ${CMAKE_BINARY_DIR})
endforeach()
\end{lstlisting}


\section{Kommandozeilenargumente}
Die einzelnen Schritte der Pipeline werden mittels Kommandozeilenargumente konfiguriert.
Zum Parsen der übergebenen Argumente wurde ein Argumentparser geschrieben.
Dieser akzeptiert Argumente in der Form \emph{-Argumentname}, wobei es egal ist wie viele Bindestriche vor dem Argumentnamen stehen.
Da nach jedem Bindestrich ein neues Argument beginnt, ist es nicht möglich Bindestriche innerhalb von Argumentnamen zu verwenden.
Dieser ist in \emph{include/argparser.hpp} spezifiziert und in \emph{src/argparser.c} implementiert.
Er beinhaltet den Namespace \emph{argparser} sowie zwei Klassen:
\begin{itemize}
\item \textbf{Argument}, repräsentiert ein Arguments (Name, Beschreibung, ob es übergeben wurde, welcher Wert übergeben wurde, ob es übergeben werden muss)
\item \textbf{ArgumentParser}, kennt alle Argumente, überprüft die übergebenen Argumente und legt fest ob und wie ein Argument übergeben wurde
\end{itemize}

Damit der \emph{ArgumentParser} auf Attribute von \emph{Argumenten} zugreifen darf, welche nicht öffentlich sein sollen, wurden diese als \emph{protected} markiert und \emph{ArgumentParser} innerhalb der Klasse \emph{Argument} als \emph{Friend Class} markiert (siehe dazu \autoref{lst:argparser_argument_friend}, Zeilen 2-3).
Auch wenn der übergebene Wert intern als String repräsentiert wird, kann er mit der Funktion \emph{getValue()} auch in andere primitive Typen konvertiert werden (\autoref{lst:argparser_argument_friend}, Zeilen 7-12).

\begin{lstlisting}[language=c++, numbers=left, breaklines=true, breakatwhitespace=false, label=lst:argparser_argument_friend]
namespace argparser {
    class Argument {
        friend class ArgumentParser;

    public:
        [..]
        template<typename T> T getValue() {
            std::istringstream in(this->value);
            T t = T();
            in >> t >> std::ws;
            return t;
        }
        [..]
    protected:
        std::string value;
        [..]
    };
    [..]
}
\end{lstlisting}

\begin{lstlisting}[language=c++, numbers=left, breaklines=true, breakatwhitespace=false, label=lst:argparser_example, caption=Argparser Verwendung]
int main(int argc, char *argv[]) {
    argparser::ArgumentParser parser("yapgt (yet another photogrammetry tool)");
    argparser::Argument a_loadCalibration("loadCalibration", "Filepath to load calibration from");    
    parser.addArgument(&a_loadCalibration);
    parser.parseArguments(argc, argv);
    if (a_loadCalibration.isFound()) {
        filesystem::path path(a_loadCalibration.getValue<string>());
    }
}
\end{lstlisting}

Der Argumentparser kann wie in \autoref{lst:argparser_example} zu sehen ist verwendet werden:\\
Zunächst wird eine Instanz von \emph{ArgumentParser} erzeugt.
Als Parameter wird der Applikationsname übergeben.
Dieser wird beim Aufruf der Applikation mit dem Argument \emph{-help} angezeigt.
Danach wird ein Argument erzeugt.
Als Parameter werden der Name des Argumentes, sowie eine Beschreibung für Hilfe übergeben.
Danach wird das Argument dem ArgumentParser hinzugefügt.
Mit der Funktion \emph{parseArguments(argc, argv)} wird das eigentliche Verarbeiten der Argumente durchgeführt.
Mittels der Funktion \emph{isFound()} wird nun überprüft, ob das Argument übergeben wurde.
Der übergebene Wert kann nun mittels \emph{getValue<string>()} als String weiter verarbeitet werden.

In \autoref{tab:arguments} sind alle verfügbaren Argumente so wie eine Beschreibung aufgelistet.

\begin{table}[]
\centering
\begin{tabularx}{\textwidth}{ |l|X| }
\hline
Name              & Beschreibung                                                                                                              \\ \hline
loadCalibration   & Dateipfad, aus dem die Kalibrierung geladen wird, kann nicht gleichzeitig mit calibrationImages werden                    \\
saveCalibration   & Dateipfad, in dem die Kalibrierung gespeichert wird                                                                       \\
calibrationImages & Ordnerpfad, Bilder welche zur Kalibrierung verwendet werden, kann nicht gleichzeitig mit loadCalibration verwendet werden \\
calibrateRow      & Anzahl der Zeilen des Kalibrierungsmusters                                                                                \\
calibrateColumn   & Anzahl der Spalten des Kalibrierungsmusters                                                                               \\
matchImages       & Ordnerpfad, Bilder, welche zum Matching verwendet werden                                                                  \\
out               & Dateipfad, in den die Punkte exportiert werden                                                                            \\
matchOutput       & Ordnerpfad, visueller Export aller Matches                                                                                \\ \hline
\end{tabularx}
\caption{Übersicht über alle verfügbaren Argumente}
\label{tab:arguments}
\end{table}


\section{Pipeline}


\section{Kamera Kalibrierung}
Die Kalibrierung der Kamera wird von der Klasse \emph{Calibration} durchgeführt.
\emph{KameraMatrix}, \emph{OptimalMatrix} sowie \emph{DistoritonCoefficients} werden in selbiger vorgehalten, so dass einfach ein \emph{Calibration} Objekt an die weiteren Schritte der Pipeline weitergeleitet werden.
Die Klasse \emph{Calibration} ist in \emph{include/calibration.hpp} spezifiziert und in \emph{src/calibration.cpp} implementiert.
Der Konstruktor benötigt keine Argumente.
Die Klasse stellt folgende Methoden zur Verfügung:
\begin{itemize}
\item \emph{cv::Mat\& getCameraMatrix()} gibt die Kamera-Matrix zurück
\item \emph{void calibrate(std::vector<std::filesystem::path> imageFiles, cv::Size boardSize)} führt die eigentliche Kalibrierung der Kamera anhand der übergebenen Bilder durch, siehe dazu \autoref{sec:calibration-calibration}
\item \emph{void loadCalibration(std::filesytem::path filepath)} Lädt die Kalibrierung aus der angegebenen Datei, siehe dazu \autoref{sec:calibration-load-save}
\item \emph{void saveCalibration(std::filesystem::path filepath)} Speichert die Kalibrierung in der angegebenen Datei, siehe dazu \autoref{sec:calibration-load-save}
\item \emph{void undistortImage(const cv::Mat\& image, cv::Mat\& undistoredImage)} entzerrt das übergebene Bild und speichert das entzerrte Bild in \emph{undistoredImage}
\end{itemize}

\subsection{Kalibrierung}\label{sec:calibration-calibration}
Zunächst wird ein Vektor aus Punkten erzeugt welcher die Koordinaten aller Schachbrettfelder hält.
Die Z-Komponente des Vektors ist dabei immer 0.
Es wird davon ausgegangen, dass das Schachbrettmuster auf allen Bildern vollständig zu sehen ist.
Deshalb kann dieser Vektor später für jedes Bild verwendet werden.

Danach wird jedes Bild geladen und mit dem Faktor zwei runter skaliert um die Berechnungen zu beschleunigen.
Dafür wird OpenCVs \emph{resize} Funktion verwendet.
Danach wird das Bild in ein Graustufenbild konvertiert.
Dann wird OpenCVs \emph{findChessboardCorners} aufgerufen.
Als Parameter werden das Bild, die Dimension des Schachbretts, einen Vektor von Punkten, in welchem die gefundenen Ecken gespeichert werden, sowie die Flags \emph{CALIB\_CB\_ADAPTIVE\_THRESH} und \emph{CALIB\_CB\_FILTER\_QUADS} verwendet.
\emph{CALIB\_CB\_ADAPTIVE\_THRESH} sorgt dafür, dass adaptive Schwellenwerte verwendet werden so das die Kacheln des Schachbretts nicht vollkommen schwarz bzw. weiß sein muss.
Es wird, entgegen des Standardverhalten, kein Schwellwert anhand der durchschnittlichen Helligkeit verwendet.
Nach dem setzen des Schwellwerts versucht der Algorithmus Vierecke zu lokalisieren.
Wenn \emph{CALIB\_CB\_FILTER\_QUADS} gesetzt ist, werden zusätzlich weitere Einschränkungen getroffen um falsche Vierecke auszuschließen.
Falls \emph{findChessboardCorners} ein Schachbrettmuster erkannt hat, wird die Präzision der gefundenen Ecken mittels \emph{cornerSubPix} erhöht.
Auch wenn \emph{cornerSubPix} von \emph{findChessboardCorners} automatisch aufgerufen wird, so kann die Präzision noch weiter erhöht werden, in dem \emph{cornerSubPix} erneut mit enger gewählten Parametern aufgerufen wird.

Nach dem dieser Prozess für jedes Bild durchgeführt wurde, wird die eigentliche Kalibrierung durchgeführt.
Dafür wird OpenCVs \emph{calibrateCamera} verwendet.
Als Parameter werden ein Vektor von Vektoren der einzelnen, gefundenen Ecken, ein Vektor von Vektoren der Schachbrett Koordinaten, die Größe der Bilder sowie Variablen für Rückgabe von Kamera-Matrix, Verzerrungskoeffizienten, Rotationsvektor sowie Translationsvektor übergeben.



\subsection{Speichern und Laden}\label{sec:calibration-load-save}
Zum Speichern und zum Laden wird OpenCVs \emph{FileStorage} verwendet.
Dieser unterstützt die Dateiformate \emph{XML}, \emph{YAML} sowie \emph{JSON}.
Konkret gespeichert werden die Matrizen \emph{cameraMatrix}, \emph{optimalCameraMatrix} sowie \emph{distortionCoefficients}.
Für jede dieser Variablen wurde eine Konstante definiert welche dem FileStorage als Schlüssel dient.
In \autoref{lst:opencv_filestorage} ist zu sehen, wie mit einem \emph{FileStorage} Objekt gearbeitet werden kann.
Bei \emph{cameraMatrixSerName} sowie \emph{distortionCoefficientsSerName} handelt es sich dabei um die konstanten Schlüssel unter welchen die Daten abgespeichert werden.
Zu beachten ist, dass beim Erzeugen des \emph{FileStorage} Objekts kein Format angegeben wurde.
Das zu verwendende Format wird anhand der Dateiendung bestimmt.

\begin{lstlisting}[language=c++, numbers=left, breaklines=true, breakatwhitespace=false, label=lst:opencv_filestorage, caption=Schreiben mit OpenCV Filestorage]
cv::FileStorage fs(filepath.string(), cv::FileStorage::WRITE);
fs << cameraMatrixSerName << cameraMatrix;
fs << distortionCoefficientsSerName << distortionCoefficients;
fs.release();
\end{lstlisting}

Analog zum Speichern kann \emph{FileStorage} zum Lesen verwendet werden (siehe \autoref{lst:opencv_filestorage_read}.
Dafür kann man auf das \emph{FileStorage} Objekt wie auf ein assoziatives Array zugreifen (Zeile 2).
Zusätzlich kann dann der Typ des Rückgabewerts festgelegt werden.
In diesem Beispiel wird der unter dem Schlüssel \emph{cameraMatrixSerName} gespeicherte Wert als OpenCV Matrix geliefert.

\begin{lstlisting}[language=c++, numbers=left, breaklines=true, breakatwhitespace=false, label=lst:opencv_filestorage_read, caption=Lesen mit OpenCV Filestorage]
FileStorage fs(filepath.string(), FileStorage::READ);
cameraMatrix = fs[cameraMatrixSerName].mat();
distortionCoefficients = fs[distortionCoefficientsSerName].mat();
fs.release();
\end{lstlisting}


Eine von \emph{FileStorage} erzeugte XML Datei ist in \autoref{appendix:opencv_filestorage_example} \nameref{appendix:opencv_filestorage_example} zu sehen.

\section{Feature Identifizierung}
Zur Feature Identifizierung wird der Algorithmus \emph{Scale-Invariant Feature Transform} (SIFT) verwendet.
SIFT wurde gewählt da...

Die Feature Identifizierung findet in der Funktion \emph{generateSequence} der Klasse \emph{SequenceMatcher} statt.
Hierzu werden für jedes Bild folgende Schritte durchgeführt:\\
Zunächst wird ein ImageContainer-Struktur erzeugt.
Danach wird das Bild mittels \emph{cv::imread} als \emph{cv::Mat} eingelesen.
Diese Matrix wird nun mittels \emph{resize} um den Downsampling Faktor herunterskaliert um die Bearbeitung zu beschleunigen.
Danach wird die Methode \emph{undistortImage} des übergebenen \emph{Calibration} Objekts verwendet um das Bild zu entzerren.
Danach wird eine Instanz der OpenCV Implementierung von SIFT erzeugt.
Dabei werden als Parameter für \emph{nFeatures} 0, um alle Features zu erhalten, für \emph{nOctaveLayers} 3, für \emph{contrastThreshold} 0.04, für \emph{edgeThreshold} 10 sowie für \emph{sigma} 1.6 übergeben.
Zuletzt wird die Funktion \emph{detectAndCompute} der SIFT Instanz aufgerufen.
Als Parameter wird hier das eingelesene Bild, ein Leeres Array (\emph{cv::noArray}) als Maske sowie Pointer für die Rückgabe der Keypoints sowie der Deskriptoren verwendet.

\section{Feature Matching}

\section{Rekonstruktion}

\section{Export}
\subsection{PLY Format}
\subsection{Farben}
